{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code from https://www.analyticsvidhya.com/blog/2018/11/introduction-text-summarization-textrank-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/tomasmizera/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/tennis_articles.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>article_title</th>\n",
       "      <th>article_text</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I do not have friends in�tennis, says Maria Sh...</td>\n",
       "      <td>Maria Sharapova has basically no friends as te...</td>\n",
       "      <td>https://www.tennisworldusa.org/tennis/news/Mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Federer defeats Medvedev to advance to 14th Sw...</td>\n",
       "      <td>BASEL, Switzerland (AP) � Roger Federer advanc...</td>\n",
       "      <td>http://www.tennis.com/pro-game/2018/10/copil-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tennis: Roger Federer ignored deadline set by ...</td>\n",
       "      <td>Roger Federer has revealed that organisers of ...</td>\n",
       "      <td>https://scroll.in/field/899938/tennis-roger-fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Nishikori to face off against Anderson in Vien...</td>\n",
       "      <td>Kei Nishikori will try to end his long losing ...</td>\n",
       "      <td>http://www.tennis.com/pro-game/2018/10/nishiko...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Roger Federer has made this huge change to ten...</td>\n",
       "      <td>Federer, 37, first broke through on tour over ...</td>\n",
       "      <td>https://www.express.co.uk/sport/tennis/1036101...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Rafael Nadal: World No 1 ARRIVES for Paris Mas...</td>\n",
       "      <td>Nadal has not played tennis since he was force...</td>\n",
       "      <td>https://www.express.co.uk/sport/tennis/1037119...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>TENNIS.COM PODCAST: POINT DEFENSE, RANKING DRO...</td>\n",
       "      <td>Tennis giveth, and tennis taketh away. The end...</td>\n",
       "      <td>http://www.tennis.com/pro-game/2018/10/tennisc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Tennis journalist�s heartbreaking insight on T...</td>\n",
       "      <td>I PLAYED golf last week with Todd Reid. He pic...</td>\n",
       "      <td>https://www.foxsports.com.au/tennis/tennis-jou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                      article_title  \\\n",
       "0           1  I do not have friends in�tennis, says Maria Sh...   \n",
       "1           2  Federer defeats Medvedev to advance to 14th Sw...   \n",
       "2           3  Tennis: Roger Federer ignored deadline set by ...   \n",
       "3           4  Nishikori to face off against Anderson in Vien...   \n",
       "4           5  Roger Federer has made this huge change to ten...   \n",
       "5           6  Rafael Nadal: World No 1 ARRIVES for Paris Mas...   \n",
       "6           7  TENNIS.COM PODCAST: POINT DEFENSE, RANKING DRO...   \n",
       "7           8  Tennis journalist�s heartbreaking insight on T...   \n",
       "\n",
       "                                        article_text  \\\n",
       "0  Maria Sharapova has basically no friends as te...   \n",
       "1  BASEL, Switzerland (AP) � Roger Federer advanc...   \n",
       "2  Roger Federer has revealed that organisers of ...   \n",
       "3  Kei Nishikori will try to end his long losing ...   \n",
       "4  Federer, 37, first broke through on tour over ...   \n",
       "5  Nadal has not played tennis since he was force...   \n",
       "6  Tennis giveth, and tennis taketh away. The end...   \n",
       "7  I PLAYED golf last week with Todd Reid. He pic...   \n",
       "\n",
       "                                              source  \n",
       "0  https://www.tennisworldusa.org/tennis/news/Mar...  \n",
       "1  http://www.tennis.com/pro-game/2018/10/copil-s...  \n",
       "2  https://scroll.in/field/899938/tennis-roger-fe...  \n",
       "3  http://www.tennis.com/pro-game/2018/10/nishiko...  \n",
       "4  https://www.express.co.uk/sport/tennis/1036101...  \n",
       "5  https://www.express.co.uk/sport/tennis/1037119...  \n",
       "6  http://www.tennis.com/pro-game/2018/10/tennisc...  \n",
       "7  https://www.foxsports.com.au/tennis/tennis-jou...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Maria Sharapova has basically no friends as te...\n",
       "1    BASEL, Switzerland (AP) � Roger Federer advanc...\n",
       "2    Roger Federer has revealed that organisers of ...\n",
       "3    Kei Nishikori will try to end his long losing ...\n",
       "4    Federer, 37, first broke through on tour over ...\n",
       "5    Nadal has not played tennis since he was force...\n",
       "6    Tennis giveth, and tennis taketh away. The end...\n",
       "7    I PLAYED golf last week with Todd Reid. He pic...\n",
       "Name: article_text, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['article_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "sentences = []\n",
    "for s in df['article_text']:\n",
    "    sentences.append(sent_tokenize(s))\n",
    "    \n",
    "sentences = [ y for x in sentences for y in x ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['But ultimately tennis is just a very small part of what we do.',\n",
       " \"There are so many other things that we're interested in, that we do.'\"]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[16:18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_sentences = pd.Series(sentences).str.replace(\"[^a-zA-Z]\", \" \")\n",
    "clean_sentences = [s.lower() for s in clean_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/tomasmizera/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(sen):\n",
    "    sen_new = \" \".join([i for i in sen if i not in stop_words])\n",
    "    return sen_new\n",
    "\n",
    "clean_sentences = [remove_stopwords(r.split()) for r in clean_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = CountVectorizer()\n",
    "# vectorizer.fit([' '.join(clean_sentences)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence_vectors = []\n",
    "# for i in clean_sentences:\n",
    "#     if len(i) != 0:\n",
    "#         v = sum([vectorizer.vocabulary_.get(w, np.zeros((100,))) for w in i.split()])/(len(i.split())+0.001)\n",
    "#         v = np.array(v)\n",
    "#     else:\n",
    "#         v = np.zeros((100,))\n",
    "#     sentence_vectors.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence_vectors[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizer v2 - Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings = {}\n",
    "f = open('../data/glove/glove.6B.100d.txt', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    word_embeddings[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_vectors = []\n",
    "for i in clean_sentences:\n",
    "    if len(i) != 0:\n",
    "        v = sum([word_embeddings.get(w, np.zeros((100,))) for w in i.split()])/(len(i.split())+0.001)\n",
    "    else:\n",
    "        v = np.zeros((100,))\n",
    "    sentence_vectors.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.05148256,  0.11054468,  0.6949994 ,  0.1891681 , -0.09580777],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_vectors[:1][0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity matrix\n",
    "sim_mat = np.zeros([len(sentences), len(sentences)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "    for j in range(len(sentences)):\n",
    "        if i != j:\n",
    "            sim_mat[i][j] = cosine_similarity(sentence_vectors[i].reshape(1,100), sentence_vectors[j].reshape(1,100))[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx_graph = nx.from_numpy_array(sim_mat)\n",
    "scores = nx.pagerank(nx_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_sentences = sorted(((scores[i],s) for i, s in enumerate(sentences)), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.008542794969989746, '�I was on a nice trajectorythen,� Reid recalled.�If I hadn�t got sick, I think I could have started pushing towards the second week at the slams and then who knows.� Duringa comeback attempt some five years later, Reid added Bernard Tomic and 2018 US Open Federer slayer John Millman to his list of career scalps.')\n",
      "(0.7500584255627886, 'Major players feel that a big event in late November combined with one in January before the Australian Open will mean too much tennis and too little rest.')\n",
      "(0.008452754148043057, \"So I'm not the one to strike up a conversation about the weather and know that in the next few minutes I have to go and try to win a tennis match.\")\n",
      "(0.008446753121153963, 'Speaking at the Swiss Indoors tournament where he will play in Sunday�s final against Romanian qualifier Marius Copil, the world number three said that given the impossibly short time frame to make a decision, he opted out of any commitment.')\n",
      "(0.008431508154861666, 'Currently in ninth place, Nishikori with a win could move to within 125 points of the cut for the eight-man event in London next month.')\n",
      "(0.008430546272200658, 'Exhausted after spending half his round deep in the bushes searching for my ball, as well as those of two other golfers he�d never met before, our incredibly giving designated driver asked if we didn�t mind going straight home after signing off so he could rest up a little before heading to work.')\n",
      "(0.008428407515870427, '�I felt like the best weeks that I had to get to know players when I was playing were the Fed Cup weeks or the Olympic weeks, not necessarily during the tournaments.')\n",
      "(0.008416201908159608, \"�I just felt like it really kind of changed where people were a little bit, definitely in the '90s, a lot more quiet, into themselves, and then it started to become better.� Meanwhile, Federer is hoping he can improve his service game as he hunts his ninth Swiss Indoors title this week.\")\n",
      "(0.0084071948946562, 'The former Wimbledon junior champion was full of hope, excited about getting his life back together after a troubled few years and a touch-and-go battle with pancreatitis.')\n",
      "(0.008361661959494508, 'He used his first break point to close out the first set before going up 3-0 in the second and wrapping up the win on his first match point.')\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(ranked_sentences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_sentences[1] = (ranked_sentences[1][0] + (0.89-0.23)/max(0.89, 0.23), ranked_sentences[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7415730337078652"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.89-0.23)/max(0.89, 0.23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another option https://www.analyticsvidhya.com/blog/2020/12/tired-of-reading-long-articles-text-summarization-will-make-your-task-easier/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
